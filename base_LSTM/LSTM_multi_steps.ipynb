{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "119189cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2668c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = [], []\n",
    "    #i: n_in, n_in-1, ..., 1，为滞后期数\n",
    "    #分别代表t-n_in, ... ,t-1期\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    #i: 0, 1, ..., n_out-1，为超前预测的期数\n",
    "    #分别代表t，t+1， ... ,t+n_out-1期\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ebcada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(filepath, n_in, n_out=30, n_vars=4, train_proportion=0.8):\n",
    "    #读取数据集\n",
    "    dataset = pd.read_csv(filepath)\n",
    "    #设置时间戳索引\n",
    "    dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "    dataset.set_index(\"date\", inplace=True)\n",
    "    values = dataset.values\n",
    "    #保证所有数据都是float32类型\n",
    "    values = values.astype('float32')\n",
    "    #变量归一化\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(values)\n",
    "    #将时间序列问题转化为监督学习问题\n",
    "    reframed = series_to_supervised(scaled, n_in, n_out)\n",
    "    #取出保留的变量\n",
    "    contain_vars = []\n",
    "    for i in range(1, n_in+1):\n",
    "        contain_vars += [('var%d(t-%d)' % (j, i)) for j in range(1,n_vars+1)]  \n",
    "    data = reframed [ contain_vars + ['var1(t)'] + [('var1(t+%d)' % (j)) for j in range(1,n_out)]]\n",
    "    #修改列名\n",
    "    col_names = ['Y', 'X1', 'X2', 'X3']\n",
    "    contain_vars = []\n",
    "    for i in range(n_vars):\n",
    "        contain_vars += [('%s(t-%d)' % (col_names[i], j)) for j in range(1,n_in+1)]  \n",
    "    data.columns = contain_vars +  ['Y(t)'] + [('Y(t+%d)' % (j)) for j in range(1,n_out)]\n",
    "    #分隔数据集，分为训练集和测试集\n",
    "    values = data.values\n",
    "    n_train = round(data.shape[0]*train_proportion)\n",
    "    train = values[:n_train, :]\n",
    "    test = values[n_train:, :]\n",
    "    #分隔输入X和输出y\n",
    "    train_X, train_y = train[:, :n_in*n_vars], train[:, n_in*n_vars:]\n",
    "    test_X, test_y = test[:, :n_in*n_vars], test[:, n_in*n_vars:]\n",
    "    #将输入X改造为LSTM的输入格式，即[samples,timesteps,features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], n_in, n_vars))\n",
    "    test_X = test_X.reshape((test_X.shape[0], n_in, n_vars))\n",
    "    return scaler, data, train_X, train_y, test_X, test_y, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b71cf0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './data/data.csv'  # r'C:\\Users\\87689\\Desktop\\国贸实习\\Premium\\导出文件.csv'\n",
    "n_in = 15\n",
    "n_out = 30\n",
    "\n",
    "data_prepare = prepare_data(filepath,n_in, n_out)\n",
    "scalar, data, train_X, train_y, test_X, test_y, dataset = data_prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28a1967a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 15, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c9e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lstm(data_prepare, n_neurons=50, n_batch=72, n_epoch=100, loss='mae', optimizer='adam', repeats=1):\n",
    "    train_X = data_prepare[2]\n",
    "    train_y = data_prepare[3]\n",
    "    test_X = data_prepare[4]\n",
    "    test_y = data_prepare[5]\n",
    "    model_list = []\n",
    "    for i in range(repeats):\n",
    "        #设计神经网络\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(n_neurons, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "        model.add(Dense(train_y.shape[1]))\n",
    "        model.compile(loss=loss, optimizer=optimizer)\n",
    "        #拟合神经网络\n",
    "        history = model.fit(train_X, train_y, epochs=n_epoch, batch_size=n_batch, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
    "        #画出学习过程\n",
    "        p1 = plt.plot(history.history['loss'], color='blue', label='train')\n",
    "        p2 = plt.plot(history.history['val_loss'], color='yellow',label='test')\n",
    "        #保存model\n",
    "        model_list.append(model)\n",
    "    plt.legend([\"train\",\"test\"])\n",
    "    plt.show()\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac87ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_predict(model, data_prepare):\n",
    "    scaler = data_prepare[0]\n",
    "    test_X = data_prepare[4]\n",
    "    test_y = data_prepare[5]\n",
    "    #做出预测\n",
    "    yhat = model.predict(test_X)\n",
    "    #将测试集上的预测值还原为原来的数据维度\n",
    "    scale_new = MinMaxScaler()\n",
    "    scale_new.min_, scale_new.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "    inv_yhat = scale_new.inverse_transform(yhat)\n",
    "    #将测试集上的实际值还原为原来的数据维度\n",
    "    inv_y = scale_new.inverse_transform(test_y)\n",
    "    return inv_yhat, inv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc4ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每一步预测的RMSE\n",
    "def evaluate_forecasts(test, forecasts, n_out):\n",
    "    rmse_dic = {}\n",
    "    for i in range(n_out):\n",
    "        actual = [float(row[i]) for row in test]\n",
    "        predicted = [float(forecast[i]) for forecast in forecasts]\n",
    "        rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "        rmse_dic['t+' + str(i+1) + ' RMSE'] = rmse\n",
    "    return rmse_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b107876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#以原始数据为背景画出预测数据\n",
    "def plot_forecasts(series, forecasts):\n",
    "    #用蓝色画出原始数据集\n",
    "    plt.plot(series.values)\n",
    "    n_seq = len(forecasts[0])\n",
    "    #用红色画出预测值\n",
    "    for i in range(1,len(forecasts)+1):\n",
    "        xaxis = [x for x in range(i, i+n_seq+1)]\n",
    "        yaxis = [float(series.iloc[i-1,0])] + list(forecasts[i-1])\n",
    "        plt.plot(xaxis, yaxis, color='red')\n",
    "    #展示图像\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2f9ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义需要的变量\n",
    "filepath = '/data/data.csv'  # r'C:\\Users\\87689\\Desktop\\国贸实习\\Premium\\导出文件.csv'\n",
    "n_in = 15\n",
    "n_out = 30\n",
    "n_vars = 4\n",
    "n_neuron = 5\n",
    "n_batch = 16\n",
    "n_epoch = 200\n",
    "repeats = 5\n",
    "inv_yhat_list = []\n",
    "inv_y_list = []\n",
    "\n",
    "data_prepare = prepare_data(filepath,n_in, n_out)\n",
    "scaler, data, train_X, train_y, test_X, test_y, dataset = data_prepare\n",
    "model_list = fit_lstm(data_prepare, n_neuron, n_batch, n_epoch,repeats=repeats)\n",
    "for i in range(len(model_list)):\n",
    "    model = model_list[i]\n",
    "    inv_yhat = lstm_predict(model, data_prepare)[0]\n",
    "    inv_y = lstm_predict(model, data_prepare)[1]\n",
    "    inv_yhat_list.append(inv_yhat)\n",
    "    inv_y_list.append(inv_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5731985",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat_ave = np.zeros(inv_y.shape)\n",
    "for i in range(repeats):\n",
    "    inv_yhat_ave += inv_yhat_list[i]\n",
    "    \n",
    "inv_yhat_ave = inv_yhat_ave/repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c689fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dic_list = []\n",
    "for i in range(len(model_list)):\n",
    "    inv_yhat = inv_yhat_list[i]\n",
    "    inv_y = inv_y_list[i]\n",
    "    rmse_dic = evaluate_forecasts(inv_y, inv_yhat, n_out)\n",
    "    rmse_dic_list.append(rmse_dic)\n",
    "\n",
    "rmse_dic_list.append(evaluate_forecasts(inv_y, inv_yhat_ave, n_out))\n",
    "\n",
    "df_dic = {}\n",
    "for i in range(len(rmse_dic_list) - 1):\n",
    "    df_dic['第' + str(i+1) + '次'] = pd.Series(rmse_dic_list[i])\n",
    "    \n",
    "df_dic['平均'] = pd.Series(rmse_dic_list[i+1])\n",
    "rmse_df = pd.DataFrame(df_dic)\n",
    "rmse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f4dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = inv_yhat_ave[0].shape\n",
    "erro_rate = np.zeros(s)\n",
    "for i in range(len(inv_y)):\n",
    "    erro_rate += inv_yhat_ave[i]/inv_y[i]-1\n",
    "\n",
    "erro_rate_ave = erro_rate/len(inv_y)\n",
    "err_df = pd.DataFrame(pd.Series(erro_rate_ave))\n",
    "err_df.columns = ['平均预测错误率']\n",
    "err_df.index = ['超前%d步预测' % (i+1) for i in range(n_out)]\n",
    "err_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a42a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_prepare[6]\n",
    "test_X = data_prepare[4]\n",
    "n_real = len(dataset)-len(test_X)-len(inv_yhat_ave[0])\n",
    "#多画一个\n",
    "y_real = pd.DataFrame(dataset['Y'][n_real:n_real+10+30])\n",
    "plot_forecasts(y_real, inv_yhat_ave[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b9f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_real = len(dataset)-len(test_X)-len(inv_yhat[0])\n",
    "#多画一个\n",
    "y_real = pd.DataFrame(dataset['Y'][n_real:])\n",
    "plot_forecasts(y_real, inv_yhat_ave)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dan_traff",
   "language": "python",
   "name": "dan_traff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
