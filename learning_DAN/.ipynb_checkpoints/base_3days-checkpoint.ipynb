{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.engine.topology import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_loss_func(preds, labels):\n",
    "    mask = labels > 5\n",
    "    return np.mean(np.fabs(labels[mask]-preds[mask])/labels[mask])\n",
    "\n",
    "def smape_loss_func(preds, labels):\n",
    "    mask= labels > 5\n",
    "    return np.mean(2*np.fabs(labels[mask]-preds[mask])/(np.fabs(labels[mask])+np.fabs(preds[mask])))\n",
    "\n",
    "def mae_loss_func(preds, labels):\n",
    "    mask= labels > 5\n",
    "    return np.fabs((labels[mask]-preds[mask])).mean()\n",
    "\n",
    "def eliminate_nan(b):\n",
    "    a = np.array(b)\n",
    "    c = a[~np.isnan(a)]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#载入最近路段数据，流量数据\n",
    "# distance = np.array(pd.read_csv('video_link_dis.csv',header = None))\n",
    "near_road = np.array(pd.read_csv('../data/network/2small_network_nearest_road_id.csv',header = 0))\n",
    "flow = np.array(pd.read_csv(\"../data/network/2small_network_speed.csv\", header= 0)) #注意header=0 or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 5, 12, 30)\n",
      "(1650, 30, 3)\n",
      "(1650, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "# 利用滑动窗口的方式，重构数据为(n，最近路段数，输入时间窗，总路段数)的形式\n",
    "\n",
    "k = 5 # 参数k为需考虑的最近路段数\n",
    "t_p = 29 # 参数t_p为总时间序列长度（天）\n",
    "t_input = 12 #参数t_input为输入时间窗(8min颗粒度)\n",
    "t_pre = 3 #参数t_pre为预测时间窗(8min颗粒度) 颗粒度？\n",
    "num_links = 30 #参数num_links为总路段数\n",
    "\n",
    "\n",
    "image = []\n",
    "for i in range(np.shape(near_road)[0]):\n",
    "    road_id = []\n",
    "    for j in range(k):\n",
    "        road_id.append(near_road[i][j])\n",
    "    image.append(flow[road_id, :])\n",
    "image1 = np.reshape(image, [-1, k, len(flow[0,:])])\n",
    "image2 = np.transpose(image1,(1,2,0))\n",
    "image3 = []\n",
    "label = []\n",
    "day = []\n",
    "\n",
    "for i in range(19, t_p):  # 10 days in total\n",
    "    for j in range(180-t_input-t_pre):\n",
    "        image3.append(image2[:, i*180+j:i*180+j+t_input, :][:])\n",
    "        label.append(flow[:, i*180+j+t_input:i*180+j+t_input+t_pre][:])\n",
    "        day.append(flow[:, (i-1)*180+j+t_input:(i-1)*180+j+t_input+t_pre][:])\n",
    "\n",
    "image3 = np.asarray(image3)\n",
    "label = np.asarray(label)\n",
    "day =  np.asarray(day)\n",
    "\n",
    "print(np.shape(image3))\n",
    "print(np.shape(label))\n",
    "print(np.shape(day))\n",
    "\n",
    "#划分前80%数据为训练集，最后20%数据为测试集\n",
    "prop = 0.3\n",
    "image_train = image3[:int(np.shape(image3)[0]*prop)]\n",
    "image_test = image3[int(np.shape(image3)[0]*prop):]\n",
    "label_train = label[:int(np.shape(label)[0]*prop)]\n",
    "label_test = label[int(np.shape(label)[0]*prop):]\n",
    "\n",
    "day_train = day[:int(np.shape(day)[0]*prop)]\n",
    "day_test = day[int(np.shape(day)[0]*prop):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define merge layer\n",
    "class Merge_Layer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Merge_Layer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.para1 = self.add_weight(shape=(input_shape[0][1], input_shape[0][2]),\n",
    "                                     initializer='uniform', trainable=True,\n",
    "                                     name='para1')\n",
    "        self.para2 = self.add_weight(shape=(input_shape[1][1], input_shape[1][2]),\n",
    "                                     initializer='uniform', trainable=True,\n",
    "                                     name='para2')\n",
    "        super(Merge_Layer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mat1 = inputs[0]\n",
    "        mat2 = inputs[1]\n",
    "        output = mat1 * self.para1 + mat2 * self.para2\n",
    "        # output = mat1 * 0.1 + mat2 * 0.9\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_data (InputLayer)         (None, 5, 12, 30)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 5, 12, 30)    120         input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 5, 12, 30)    8130        batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 5, 12, 30)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 5, 12, 30)    120         average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 5, 12, 30)    8130        batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 12, 30)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1800)         0           average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1800)         7200        flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1800)         0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 180)          324180      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 90)           16290       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 30, 3)        0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_HA (InputLayer)           (None, 30, 3)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge__layer_4 (Merge_Layer)    (None, 30, 3)        180         reshape_4[0][0]                  \n",
      "                                                                 input_HA[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 364,350\n",
      "Trainable params: 360,630\n",
      "Non-trainable params: 3,720\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_data = keras.Input(shape=(k,t_input,num_links), name='input_data')\n",
    "input_HA = keras.Input(shape=(num_links, t_pre), name='input_HA')\n",
    "\n",
    "x = keras.layers.BatchNormalization(input_shape =(k,t_input,num_links))(input_data)\n",
    "\n",
    "x = keras.layers.Conv2D(\n",
    "                           filters = 30,\n",
    "                           kernel_size = 3,\n",
    "                           strides = 1,\n",
    "                           padding=\"SAME\",\n",
    "                           activation='relu')(x)\n",
    "\n",
    "x = keras.layers.AveragePooling2D(pool_size = (2,2),\n",
    "                                strides = 1,\n",
    "                                padding = \"SAME\",\n",
    "                                )(x)\n",
    "\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = keras.layers.Conv2D(\n",
    "                       filters = 30,\n",
    "                       kernel_size = 3,\n",
    "                       strides = 1,\n",
    "                       padding=\"SAME\",\n",
    "                       activation='relu')(x)\n",
    "\n",
    "x = keras.layers.AveragePooling2D(pool_size = (2,2),\n",
    "                                strides = 1,\n",
    "                                padding = \"SAME\",\n",
    "                                )(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "x = keras.layers.Dense(num_links*2*t_pre, activation='relu', name='dense_1')(x)\n",
    "x = keras.layers.Dense(num_links*t_pre, activation='relu', name='dense_2')(x)\n",
    "\n",
    "output = keras.layers.Reshape((num_links,t_pre))(x)\n",
    "\n",
    "output_final = Merge_Layer()([output, input_HA])\n",
    "\n",
    "# construct model\n",
    "finish_model = keras.models.Model([input_data,input_HA], [output_final])\n",
    "\n",
    "finish_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "finish_model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = image_train\n",
    "X_HA_train = day_train\n",
    "label_train = label_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 495 samples, validate on 1155 samples\n",
      "Epoch 1/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 403.3824 - val_loss: 402.4990\n",
      "Epoch 2/100\n",
      "495/495 [==============================] - 0s 187us/step - loss: 399.2983 - val_loss: 396.5200\n",
      "Epoch 3/100\n",
      "495/495 [==============================] - 0s 159us/step - loss: 393.7428 - val_loss: 385.8540\n",
      "Epoch 4/100\n",
      "495/495 [==============================] - 0s 163us/step - loss: 385.3124 - val_loss: 370.9505\n",
      "Epoch 5/100\n",
      "495/495 [==============================] - 0s 155us/step - loss: 372.4981 - val_loss: 351.7822\n",
      "Epoch 6/100\n",
      "495/495 [==============================] - 0s 147us/step - loss: 352.9308 - val_loss: 327.9426\n",
      "Epoch 7/100\n",
      "495/495 [==============================] - 0s 145us/step - loss: 325.2721 - val_loss: 297.3998\n",
      "Epoch 8/100\n",
      "495/495 [==============================] - 0s 153us/step - loss: 289.6896 - val_loss: 261.0139\n",
      "Epoch 9/100\n",
      "495/495 [==============================] - 0s 153us/step - loss: 250.6000 - val_loss: 230.5336\n",
      "Epoch 10/100\n",
      "495/495 [==============================] - 0s 171us/step - loss: 217.6960 - val_loss: 218.4100\n",
      "Epoch 11/100\n",
      "495/495 [==============================] - 0s 151us/step - loss: 198.4686 - val_loss: 213.6013\n",
      "Epoch 12/100\n",
      "495/495 [==============================] - 0s 149us/step - loss: 179.9110 - val_loss: 197.8561\n",
      "Epoch 13/100\n",
      "495/495 [==============================] - 0s 147us/step - loss: 166.8589 - val_loss: 182.9231\n",
      "Epoch 14/100\n",
      "495/495 [==============================] - 0s 137us/step - loss: 158.6013 - val_loss: 177.1805\n",
      "Epoch 15/100\n",
      "495/495 [==============================] - 0s 155us/step - loss: 154.8204 - val_loss: 174.1285\n",
      "Epoch 16/100\n",
      "495/495 [==============================] - 0s 169us/step - loss: 151.5224 - val_loss: 170.8364\n",
      "Epoch 17/100\n",
      "495/495 [==============================] - 0s 155us/step - loss: 146.9312 - val_loss: 168.0795\n",
      "Epoch 18/100\n",
      "495/495 [==============================] - 0s 145us/step - loss: 142.6626 - val_loss: 164.8973\n",
      "Epoch 19/100\n",
      "495/495 [==============================] - 0s 149us/step - loss: 137.7374 - val_loss: 160.3916\n",
      "Epoch 20/100\n",
      "495/495 [==============================] - 0s 147us/step - loss: 134.6600 - val_loss: 157.3377\n",
      "Epoch 21/100\n",
      "495/495 [==============================] - 0s 159us/step - loss: 130.7360 - val_loss: 155.3918\n",
      "Epoch 22/100\n",
      "495/495 [==============================] - 0s 143us/step - loss: 128.6094 - val_loss: 153.7003\n",
      "Epoch 23/100\n",
      "495/495 [==============================] - 0s 145us/step - loss: 126.4624 - val_loss: 151.2530\n",
      "Epoch 24/100\n",
      "495/495 [==============================] - 0s 139us/step - loss: 122.5718 - val_loss: 148.3543\n",
      "Epoch 25/100\n",
      "495/495 [==============================] - 0s 171us/step - loss: 120.4899 - val_loss: 146.9737\n",
      "Epoch 26/100\n",
      "495/495 [==============================] - 0s 149us/step - loss: 120.2422 - val_loss: 146.5970\n",
      "Epoch 27/100\n",
      "495/495 [==============================] - 0s 157us/step - loss: 116.1584 - val_loss: 142.8274\n",
      "Epoch 28/100\n",
      "495/495 [==============================] - 0s 147us/step - loss: 114.1397 - val_loss: 138.0731\n",
      "Epoch 29/100\n",
      "495/495 [==============================] - 0s 147us/step - loss: 110.4732 - val_loss: 138.4476\n",
      "Epoch 30/100\n",
      "495/495 [==============================] - 0s 143us/step - loss: 108.3427 - val_loss: 135.9136\n",
      "Epoch 31/100\n",
      "495/495 [==============================] - 0s 137us/step - loss: 105.9897 - val_loss: 134.1720\n",
      "Epoch 32/100\n",
      "495/495 [==============================] - 0s 135us/step - loss: 105.6393 - val_loss: 133.8517\n",
      "Epoch 33/100\n",
      "495/495 [==============================] - 0s 137us/step - loss: 103.1756 - val_loss: 131.8108\n",
      "Epoch 34/100\n",
      "495/495 [==============================] - 0s 147us/step - loss: 102.4539 - val_loss: 131.4357\n",
      "Epoch 35/100\n",
      "495/495 [==============================] - 0s 149us/step - loss: 104.1192 - val_loss: 128.6288\n",
      "Epoch 36/100\n",
      "495/495 [==============================] - 0s 139us/step - loss: 100.6495 - val_loss: 126.5963\n",
      "Epoch 37/100\n",
      "495/495 [==============================] - 0s 145us/step - loss: 98.1440 - val_loss: 124.0993\n",
      "Epoch 38/100\n",
      "495/495 [==============================] - 0s 147us/step - loss: 99.6479 - val_loss: 121.9839\n",
      "Epoch 39/100\n",
      "495/495 [==============================] - 0s 139us/step - loss: 96.3097 - val_loss: 119.8098\n",
      "Epoch 40/100\n",
      "495/495 [==============================] - 0s 141us/step - loss: 96.3556 - val_loss: 117.7217\n",
      "Epoch 41/100\n",
      "495/495 [==============================] - 0s 149us/step - loss: 97.1417 - val_loss: 116.4549\n",
      "Epoch 42/100\n",
      "495/495 [==============================] - 0s 157us/step - loss: 95.5253 - val_loss: 113.2923\n",
      "Epoch 43/100\n",
      "495/495 [==============================] - 0s 137us/step - loss: 93.5948 - val_loss: 110.3749\n",
      "Epoch 44/100\n",
      "495/495 [==============================] - 0s 141us/step - loss: 93.8815 - val_loss: 109.4706\n",
      "Epoch 45/100\n",
      "495/495 [==============================] - 0s 147us/step - loss: 93.6291 - val_loss: 109.6566\n",
      "Epoch 46/100\n",
      "495/495 [==============================] - 0s 147us/step - loss: 92.7969 - val_loss: 108.2256\n",
      "Epoch 47/100\n",
      "495/495 [==============================] - 0s 147us/step - loss: 90.1751 - val_loss: 106.5848\n",
      "Epoch 48/100\n",
      "495/495 [==============================] - 0s 145us/step - loss: 90.2763 - val_loss: 105.3913\n",
      "Epoch 49/100\n",
      "495/495 [==============================] - 0s 155us/step - loss: 89.2250 - val_loss: 104.2468\n",
      "Epoch 50/100\n",
      "495/495 [==============================] - 0s 141us/step - loss: 89.5055 - val_loss: 102.7854\n",
      "Epoch 51/100\n",
      "495/495 [==============================] - 0s 145us/step - loss: 87.8255 - val_loss: 101.8453\n",
      "Epoch 52/100\n",
      "495/495 [==============================] - 0s 141us/step - loss: 87.7955 - val_loss: 100.8793\n",
      "Epoch 53/100\n",
      "495/495 [==============================] - 0s 133us/step - loss: 86.3342 - val_loss: 100.0892\n",
      "Epoch 54/100\n",
      "495/495 [==============================] - 0s 141us/step - loss: 86.9646 - val_loss: 99.2965\n",
      "Epoch 55/100\n",
      "495/495 [==============================] - 0s 157us/step - loss: 84.4336 - val_loss: 98.2738\n",
      "Epoch 56/100\n",
      "495/495 [==============================] - 0s 143us/step - loss: 84.3535 - val_loss: 97.2922\n",
      "Epoch 57/100\n",
      "495/495 [==============================] - 0s 139us/step - loss: 85.6061 - val_loss: 96.8033\n",
      "Epoch 58/100\n",
      "495/495 [==============================] - 0s 143us/step - loss: 82.8259 - val_loss: 95.4725\n",
      "Epoch 59/100\n",
      "495/495 [==============================] - 0s 143us/step - loss: 82.1678 - val_loss: 94.7420\n",
      "Epoch 60/100\n",
      "495/495 [==============================] - 0s 143us/step - loss: 81.9681 - val_loss: 94.1455\n",
      "Epoch 61/100\n",
      "495/495 [==============================] - 0s 147us/step - loss: 80.4841 - val_loss: 93.3277\n",
      "Epoch 62/100\n",
      "495/495 [==============================] - 0s 151us/step - loss: 80.6332 - val_loss: 92.4923\n",
      "Epoch 63/100\n",
      "495/495 [==============================] - 0s 143us/step - loss: 80.5499 - val_loss: 91.7188\n",
      "Epoch 64/100\n",
      "495/495 [==============================] - 0s 149us/step - loss: 79.4898 - val_loss: 91.1051\n",
      "Epoch 65/100\n",
      "495/495 [==============================] - 0s 141us/step - loss: 77.9051 - val_loss: 89.9665\n",
      "Epoch 66/100\n",
      "495/495 [==============================] - 0s 141us/step - loss: 78.1402 - val_loss: 89.2110\n",
      "Epoch 67/100\n",
      "495/495 [==============================] - 0s 141us/step - loss: 76.9121 - val_loss: 88.7002\n",
      "Epoch 68/100\n",
      "495/495 [==============================] - 0s 147us/step - loss: 76.5824 - val_loss: 88.4602\n",
      "Epoch 69/100\n",
      "495/495 [==============================] - 0s 171us/step - loss: 75.8919 - val_loss: 87.3992\n",
      "Epoch 70/100\n",
      "495/495 [==============================] - 0s 147us/step - loss: 76.0190 - val_loss: 86.1624\n",
      "Epoch 71/100\n",
      "495/495 [==============================] - 0s 143us/step - loss: 74.8717 - val_loss: 85.0962\n",
      "Epoch 72/100\n",
      "495/495 [==============================] - 0s 145us/step - loss: 73.5675 - val_loss: 84.2486\n",
      "Epoch 73/100\n",
      "495/495 [==============================] - 0s 141us/step - loss: 74.2835 - val_loss: 83.7904\n",
      "Epoch 74/100\n",
      "495/495 [==============================] - 0s 145us/step - loss: 72.8635 - val_loss: 83.1777\n",
      "Epoch 75/100\n",
      "495/495 [==============================] - 0s 149us/step - loss: 72.4462 - val_loss: 82.2916\n",
      "Epoch 76/100\n",
      "495/495 [==============================] - 0s 139us/step - loss: 71.8745 - val_loss: 81.2640\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495/495 [==============================] - 0s 137us/step - loss: 70.4170 - val_loss: 80.5790\n",
      "Epoch 78/100\n",
      "495/495 [==============================] - 0s 145us/step - loss: 70.9400 - val_loss: 79.7012\n",
      "Epoch 79/100\n",
      "495/495 [==============================] - 0s 139us/step - loss: 70.2594 - val_loss: 78.8568\n",
      "Epoch 80/100\n",
      "495/495 [==============================] - 0s 137us/step - loss: 69.0427 - val_loss: 78.1215\n",
      "Epoch 81/100\n",
      "495/495 [==============================] - 0s 139us/step - loss: 68.3727 - val_loss: 77.2977\n",
      "Epoch 82/100\n",
      "495/495 [==============================] - 0s 148us/step - loss: 69.5994 - val_loss: 76.4908\n",
      "Epoch 83/100\n",
      "495/495 [==============================] - 0s 151us/step - loss: 67.5554 - val_loss: 75.5784\n",
      "Epoch 84/100\n",
      "495/495 [==============================] - 0s 149us/step - loss: 66.3398 - val_loss: 75.0365\n",
      "Epoch 85/100\n",
      "495/495 [==============================] - 0s 145us/step - loss: 66.7422 - val_loss: 74.5193\n",
      "Epoch 86/100\n",
      "495/495 [==============================] - 0s 141us/step - loss: 65.6433 - val_loss: 73.9161\n",
      "Epoch 87/100\n",
      "495/495 [==============================] - 0s 151us/step - loss: 65.3130 - val_loss: 73.6224\n",
      "Epoch 88/100\n",
      "495/495 [==============================] - 0s 153us/step - loss: 64.2479 - val_loss: 73.0632\n",
      "Epoch 89/100\n",
      "495/495 [==============================] - 0s 151us/step - loss: 65.0720 - val_loss: 72.7227\n",
      "Epoch 90/100\n",
      "495/495 [==============================] - 0s 153us/step - loss: 63.5751 - val_loss: 71.9818\n",
      "Epoch 91/100\n",
      "495/495 [==============================] - 0s 153us/step - loss: 63.9239 - val_loss: 71.2211\n",
      "Epoch 92/100\n",
      "495/495 [==============================] - 0s 139us/step - loss: 62.3637 - val_loss: 70.0030\n",
      "Epoch 93/100\n",
      "495/495 [==============================] - 0s 141us/step - loss: 61.5413 - val_loss: 69.1524\n",
      "Epoch 94/100\n",
      "495/495 [==============================] - 0s 139us/step - loss: 61.0108 - val_loss: 68.6546\n",
      "Epoch 95/100\n",
      "495/495 [==============================] - 0s 135us/step - loss: 61.0760 - val_loss: 68.1906\n",
      "Epoch 96/100\n",
      "495/495 [==============================] - 0s 145us/step - loss: 59.8498 - val_loss: 68.0782\n",
      "Epoch 97/100\n",
      "495/495 [==============================] - 0s 155us/step - loss: 60.4650 - val_loss: 67.1159\n",
      "Epoch 98/100\n",
      "495/495 [==============================] - 0s 155us/step - loss: 59.1808 - val_loss: 66.3622\n",
      "Epoch 99/100\n",
      "495/495 [==============================] - 0s 143us/step - loss: 60.3326 - val_loss: 65.9046\n",
      "Epoch 100/100\n",
      "495/495 [==============================] - 0s 143us/step - loss: 58.4795 - val_loss: 65.4816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2587697e4a8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型拟合与评估\n",
    "finish_model.fit([X_train,X_HA_train], label_train, epochs=100, batch_size=128,\n",
    "validation_data=([image_test,day_test], label_test))\n",
    "# finish_model.evaluate(image_test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型预测\n",
    "model_pre = finish_model.predict([image_test,day_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mape = 0.31186034260974677\n",
      "smape = 0.41198701789268316\n",
      "mae = 6.182956886307675\n"
     ]
    }
   ],
   "source": [
    "#计算各项误差指标\n",
    "\n",
    "mape_mean = mape_loss_func(model_pre, label_test)\n",
    "smape_mean = smape_loss_func(model_pre, label_test)\n",
    "mae_mean = mae_loss_func(model_pre, label_test)\n",
    "\n",
    "print('mape = ' + str(mape_mean) + '\\n' + 'smape = ' + str(smape_mean) + '\\n' + 'mae = ' + str(mae_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型保存\n",
    "finish_model.save_weights('../model/source_base.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th link\n",
      "0.17099993189057397\n",
      "2th link\n",
      "0.14873669859536603\n",
      "3th link\n",
      "0.30484981053876603\n",
      "4th link\n",
      "0.3141808410194122\n",
      "5th link\n",
      "0.6268967094883933\n",
      "6th link\n",
      "0.15414606088704982\n",
      "7th link\n",
      "0.18017541519943803\n",
      "8th link\n",
      "0.3122541093990654\n",
      "9th link\n",
      "0.3232844055910491\n",
      "10th link\n",
      "0.48301803275022187\n",
      "11th link\n",
      "0.16817282156659513\n",
      "12th link\n",
      "0.17955317456740114\n",
      "13th link\n",
      "0.6566738549945366\n",
      "14th link\n",
      "0.3227773696383946\n",
      "15th link\n",
      "0.3399377729925814\n",
      "16th link\n",
      "0.46127914501729106\n",
      "17th link\n",
      "0.16213136393067387\n",
      "18th link\n",
      "0.1583191028116414\n",
      "19th link\n",
      "0.3281313902648899\n",
      "20th link\n",
      "0.34153200386803717\n",
      "21th link\n",
      "0.18488122836206536\n",
      "22th link\n",
      "0.4688560712587645\n",
      "23th link\n",
      "0.443408022934169\n",
      "24th link\n",
      "0.3258106831312804\n",
      "25th link\n",
      "0.34339281660117454\n",
      "26th link\n",
      "0.3132195421870117\n",
      "27th link\n",
      "0.17833354355498132\n",
      "28th link\n",
      "0.31292196926944604\n",
      "29th link\n",
      "0.31288050936331996\n",
      "30th link\n",
      "0.3350558766188119\n"
     ]
    }
   ],
   "source": [
    "#计算每条路段的误差\n",
    "mape_list = []\n",
    "for i in range(num_links):\n",
    "    a1 = mape_loss_func(model_pre[:,i,:], label_test[:,i,:])\n",
    "    mape_list.append(a1)\n",
    "    print(str(i+1)+'th link')\n",
    "    print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mape_pd = pd.Series(mape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.148737\n",
       "5     0.154146\n",
       "17    0.158319\n",
       "16    0.162131\n",
       "10    0.168173\n",
       "0     0.171000\n",
       "26    0.178334\n",
       "11    0.179553\n",
       "6     0.180175\n",
       "20    0.184881\n",
       "2     0.304850\n",
       "7     0.312254\n",
       "28    0.312881\n",
       "27    0.312922\n",
       "25    0.313220\n",
       "3     0.314181\n",
       "13    0.322777\n",
       "8     0.323284\n",
       "23    0.325811\n",
       "18    0.328131\n",
       "29    0.335056\n",
       "14    0.339938\n",
       "19    0.341532\n",
       "24    0.343393\n",
       "22    0.443408\n",
       "15    0.461279\n",
       "21    0.468856\n",
       "9     0.483018\n",
       "4     0.626897\n",
       "12    0.656674\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_pd.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b092d8890fbfc1935d95d43d0881a7b3742c06492f450993a24f5c2e6237594"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "6b092d8890fbfc1935d95d43d0881a7b3742c06492f450993a24f5c2e6237594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
