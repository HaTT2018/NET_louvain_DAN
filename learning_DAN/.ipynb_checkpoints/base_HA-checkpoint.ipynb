{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设定：\n",
    "使用class0的三天数据，预测class1的七天数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_loss_func(preds, labels):\n",
    "    mask = labels > 5\n",
    "    return np.mean(np.fabs(labels[mask]-preds[mask])/labels[mask])\n",
    "\n",
    "def smape_loss_func(preds, labels):\n",
    "    mask= labels > 5\n",
    "    return np.mean(2*np.fabs(labels[mask]-preds[mask])/(np.fabs(labels[mask])+np.fabs(preds[mask])))\n",
    "\n",
    "def mae_loss_func(preds, labels):\n",
    "    mask= labels > 5\n",
    "    return np.fabs((labels[mask]-preds[mask])).mean()\n",
    "\n",
    "def eliminate_nan(b):\n",
    "    a = np.array(b)\n",
    "    c = a[~np.isnan(a)]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 class(es)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10169\\.conda\\envs\\dan_traff\\lib\\site-packages\\pandas\\core\\indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "randseed = 25\n",
    "res = 11\n",
    "\n",
    "v = pd.read_csv('../data/v_20_aggragated.csv')\n",
    "v = v.rename(columns={'Unnamed: 0': 'id'})\n",
    "det_with_class = pd.read_csv('../res/%i_res%i_id_402_withclass.csv'%(randseed, res), index_col=0)\n",
    "\n",
    "v['class_i'] = ''\n",
    "for i in range(len(v)):\n",
    "    v.loc[i, 'class_i'] = det_with_class[det_with_class['id']==v.loc[i, 'id']].iloc[0, 5]  # 5 stands for 'class_i'\n",
    "\n",
    "num_class = det_with_class['class_i'].drop_duplicates().size\n",
    "\n",
    "v_class = []\n",
    "for i in range(num_class):\n",
    "    v_class.append(v[v['class_i']==i])\n",
    "\n",
    "print('There are %i class(es)'%num_class)\n",
    "\n",
    "dist_mat = pd.read_csv('../data/dist_mat.csv', index_col=0)\n",
    "id_info = pd.read_csv('../data/id2000.csv', index_col=0)\n",
    "dist_mat.index = id_info['id2']\n",
    "dist_mat.columns = id_info['id2']\n",
    "for i in range(len(dist_mat)):\n",
    "    for j in range(len(dist_mat)):\n",
    "        if i==j:\n",
    "            dist_mat.iloc[i, j] = 0\n",
    "\n",
    "near_id = pd.DataFrame(np.argsort(np.array(dist_mat)), index = id_info['id2'], columns = id_info['id2'])\n",
    "\n",
    "def get_node(det, seg):\n",
    "    # det is one single detector id\n",
    "    # node is one single node id\n",
    "    \n",
    "    # seg = pd.read_csv('./data/segement.csv', header=None)\n",
    "    try:\n",
    "        node_info = seg[seg[6]==det]\n",
    "        node = node_info.iloc[0, 0]\n",
    "    except:\n",
    "        node_info = seg[seg[7]==det]\n",
    "        node = node_info.iloc[0, 0]\n",
    "        \n",
    "    return node\n",
    "\n",
    "def get_class_with_node(seg, v_class):\n",
    "    det_list_class = np.array([])\n",
    "    try:\n",
    "        v_class.insert(1, 'id2', '')  # id2 mean node id\n",
    "    except:\n",
    "        v_class['id2'] = ''\n",
    "        \n",
    "    for i in range(len(v_class)):\n",
    "        det_list_class = np.append(det_list_class, v_class.iloc[i, 0])\n",
    "        v_class.iloc[i, 1] = get_node(v_class.iloc[i, 0], seg)\n",
    "    \n",
    "    return det_list_class, v_class\n",
    "\n",
    "def rds_mat(old_dist_mat, det_ids):\n",
    "    # get a matrix that contains n raods that have specified node id s\n",
    "    node_ids = np.array([])\n",
    "    for i in det_ids:\n",
    "        node_ids = np.append(node_ids, get_node(i, seg))\n",
    "        \n",
    "    new_dist_mat = old_dist_mat.loc[node_ids, node_ids]\n",
    "    old_dist_mat = np.array(old_dist_mat)\n",
    "    new_near_id_mat = np.argsort(new_dist_mat)\n",
    "    return new_near_id_mat\n",
    "\n",
    "seg = pd.read_csv('../data/segement.csv', header=None)\n",
    "num_dets = 30\n",
    "\n",
    "det_list_class = []\n",
    "for i in range(num_class):\n",
    "    det_list_class_temp, v_class_temp = get_class_with_node(seg, v_class[i])\n",
    "    det_list_class.append(det_list_class_temp)\n",
    "    v_class_temp = v_class_temp[v_class_temp['id'].isin(det_list_class_temp[:num_dets])]\n",
    "    v_class[i] = v_class_temp\n",
    "\n",
    "near_road_set = []\n",
    "for i in range(num_class):\n",
    "    near_road_set.append(rds_mat(dist_mat, det_list_class[i][:num_dets]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用前三天的数据取平均，得到之后数据的预测值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_his1 = np.array(v_class[0].iloc[:, 4466-144*10-1:4466-144*9-1])\n",
    "v_his2 = np.array(v_class[0].iloc[:, 4466-144*9-1:4466-144*8-1])\n",
    "v_his3 = np.array(v_class[0].iloc[:, 4466-144*8-1:4466-144*7-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 144)\n"
     ]
    }
   ],
   "source": [
    "v_pre = (v_his1+v_his2+v_his3)/3\n",
    "print(v_pre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 864)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_pre = np.concatenate((v_pre, v_pre, v_pre, v_pre, v_pre, v_pre), axis=1)\n",
    "v_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 864)\n"
     ]
    }
   ],
   "source": [
    "label = np.array(v_class[1].iloc[:, 4466-144*7-1:4466-144-1])\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3390834774120881\n"
     ]
    }
   ],
   "source": [
    "mape = mape_loss_func(v_pre, label)\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dan_traff",
   "language": "python",
   "name": "dan_traff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
